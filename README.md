# AI-Powered RAG Assistant Using LangChain and Gradio

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) application using LangChain, IBM WatsonX, and Gradio. The project was completed as part of Coursera's "Generative AI Applications with RAG and LangChain" course.

## ğŸš€ Features
- Load documents from multiple sources using LangChain loaders
- Apply advanced text splitting strategies for token optimization
- Generate embeddings using IBM WatsonX
- Store and retrieve vectors using ChromaDB
- Implement a semantic retriever for contextual chunk retrieval
- Build a QA bot using LangChain + LLM
- Deploy an interactive interface using Gradio

## ğŸ› ï¸ Tech Stack
- LangChain
- IBM WatsonX Embeddings
- ChromaDB
- Gradio
- Python

## ğŸ–¼ï¸ Screenshots
All steps were executed within Coursera Labs. Below is the Screenshot for my Rag Chatbot.
- ğŸ¤– QA Bot Interface (`Rag_Chatbot.png`)

## ğŸ“š Course
Completed as part of Generative AI Applications with RAG and LangChain on Coursera


