# AI-Powered RAG Assistant Using LangChain and Gradio

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) application using LangChain, IBM WatsonX, and Gradio. The project was completed as part of Coursera's "Generative AI Applications with RAG and LangChain" course.

## 🚀 Features
- Load documents from multiple sources using LangChain loaders
- Apply advanced text splitting strategies for token optimization
- Generate embeddings using IBM WatsonX
- Store and retrieve vectors using ChromaDB
- Implement a semantic retriever for contextual chunk retrieval
- Build a QA bot using LangChain + LLM
- Deploy an interactive interface using Gradio

## 🛠️ Tech Stack
- LangChain
- IBM WatsonX Embeddings
- ChromaDB
- Gradio
- Python

## 🖼️ Screenshots
All steps were executed within Coursera Labs. Below is the Screenshot for my Rag Chatbot.
- 🤖 QA Bot Interface (`Rag_Chatbot.png`)

## 📚 Course
Completed as part of Generative AI Applications with RAG and LangChain on Coursera


